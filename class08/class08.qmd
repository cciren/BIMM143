---
title: "Class 08 Breast Cancer Mini Project"
author: "Irene Hsieh (PID: A16197563)"
format: pdf
---

Before dive into breast cancer project, we will finish class 7 (where we left off) first.

```{r}
url2 <- "https://tinyurl.com/expression-CSV"
rna.data <- read.csv(url2, row.names=1)
head(rna.data)
```

> Q10: How many genes and samples are in this data set? 6 genes, and 10 samples.

##Run PCA

```{r}
## Again we have to take the transpose of our data 
pca <- prcomp(t(rna.data), scale=TRUE)
 
## Simple un polished plot of pc1 and pc2
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2")
```

```{r}
summary(pca)
```

```{r}
# We have 5wt and 5ko samples
mycols <- c(rep("blue",5), rep("red",5))
mycols

plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", col = mycols)
```

I could examine which genes contribute to this first PC

```{r}
head(sort(abs(pca$rotation[,1]), decreasing = T))
```

#Analysis of Breast Cancer FNA data.

```{r}
wisc.df <- read.csv("WisconsinCancer.csv", row.names = 1)
head(wisc.df)
wisc.data <- wisc.df[,-1]
```
```{r}
diagnosis <- as.factor(wisc.df$diagnosis)
```

> Q1. How many observations are in this dataset? (columns)

```{r}
nrow(wisc.df)
ncol(wisc.data)
```

30 observations

> Q2. How many of the observations have a malignant diagnosis?

212 malignant diagnosis

```{r}
table(wisc.df$diagnosis)
```


> Q3. How many variables/features in the data are suffixed with _mean?

10 features

```{r}
length(grep("_mean$", colnames(wisc.data), value = TRUE))
```

##Principal Component Analysis

Here we will use `precomp()` on the `wisc.data` object - the one without the diagnosis column.

First, we have decide whether to use the `scale = TRUE ` argument when we run `precomp()`

We can look at the means and sd of each column. If they are similar than we are all good to go. If not we should not use `scale = TRUE`

```{r}
# Check column means and standard deviations
colMeans(wisc.data)

apply(wisc.data,2,sd)
```

```{r}
# Perform PCA on wisc.data 
wisc.pr <- prcomp( wisc.data, scale = TRUE)
# Look at summary of results
summary(wisc.pr)
```

> Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

44.27% of the original variance is captured by the first PC. 

> Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

3 PCs are required to describe at least 70% of the original variance in the data.

> Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

7 PCs are required to describe at least 90% of the original variance in the data.

```{r}
biplot(wisc.pr)
```
> Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

It is messy, we need to build our own plot. Since it is labeled by patients, it is hard to read in this plot. 

```{r}
attributes(wisc.pr)
```

> Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

The plots are more condensed on the lower side of the x-axis whiling comparing with PC1 and 2. 

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=diagnosis)
```
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,3], col=diagnosis)
```

```{r}
library(ggplot2)

pc<- as.data.frame(wisc.pr$x)

ggplot(pc)+
  aes(PC1, PC2, col = diagnosis)+
  geom_point()
```

> Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

-0.2608538

```{r}
wisc.pr$rotation["concave.points_mean",1]

```

> Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?

5 

```{r}
tbl <- summary(wisc.pr)
which (tbl$importance[3,] > 0.8)[1]
```

### Hierarcal clustering

The main function for Hierarchical clustering is called `hclust()` 
it takes a distance matrix as outcome

```{r}
d<- dist(scale(wisc.data))
wisc.hclust <- hclust(d)
plot(wisc.hclust)
```
> Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

18

```{r}
plot(wisc.hclust)
abline(h=18, col = "red")
grps <- cutree(wisc.hclust, h=18)
table(grps)
```
Come back here. later to see how our cluster grps correspond to M or B groups.

```{r}
ggplot(pc)+
  aes(PC1, PC2, col = diagnosis)+
  geom_point()
```

##5. Combineing methods

Here we will perform clustering on our PCA results rather than the original data. 

In other words we will cluster using `wisc.pr$x` - our new better variables or PCs. We can choose as many or as few PCs to use as we like.It is your call!

```{r}
d.pc <- dist(wisc.pr$x[,1:3])

wisc.pr.hclust <- hclust(d.pc,method = "ward.D2")
plot(wisc.pr.hclust)
abline(h=80, col = "red")
```

> Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.

Average method is my favorite results since it is more straightforward to understand

```{r}
grps<- cutree(wisc.pr.hclust, h =80)
table(grps)
```

We can use `table()` finction to male a cross table as well as just a count table

```{r}
table(diagnosis)
```

> Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?

2

```{r}
table(grps, diagnosis)
```

Write a note here about how to read this cross table result. 
The results indicate that our cluster 1 mostly captures cancer(M) and our cluster 2 mostly captures healthy (B) samples/individuals.

## 7. Prediction 
```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
plot(wisc.pr$x[,1:2], col=grps)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```


Q18. Which of these new patients should we prioritize for follow up based on your results?

> patient 2